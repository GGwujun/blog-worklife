<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-worklife/umi.3ec1f225.css" />
    <script>
      window.routerBase = "/blog-worklife";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>06 | jieba分词：如何基于感情色彩进行单词数量统计？ - 大师兄</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/python自动化办公实战课/04.“运算”模块扩展常用的统计、搜索和排序功能/03" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-worklife/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>后端开发<ul><li><a href="/blog-worklife/大规模数据处理实战">大规模数据处理实战</a></li></ul></span><span>工作生活<ul><li><a href="/blog-worklife/10x程序员工作法">10x程序员工作法</a></li><li><a aria-current="page" class="active" href="/blog-worklife/python自动化办公实战课">python自动化办公实战课</a></li><li><a href="/blog-worklife/人人都用得上的写作课">人人都用得上的写作课</a></li><li><a href="/blog-worklife/体验设计案例课">体验设计案例课</a></li><li><a href="/blog-worklife/基于人因的用户体验设计课">基于人因的用户体验设计课</a></li><li><a href="/blog-worklife/打造爆款短视频">打造爆款短视频</a></li><li><a href="/blog-worklife/用户体验设计实战课">用户体验设计实战课</a></li><li><a href="/blog-worklife/程序员的个人财富课">程序员的个人财富课</a></li><li><a href="/blog-worklife/程序员进阶攻略">程序员进阶攻略</a></li><li><a href="/blog-worklife/讲好故事">讲好故事</a></li><li><a href="/blog-worklife/跟着高手学复盘">跟着高手学复盘</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-worklife/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>后端开发<ul><li><a href="/blog-worklife/大规模数据处理实战">大规模数据处理实战</a></li></ul></li><li>工作生活<ul><li><a href="/blog-worklife/10x程序员工作法">10x程序员工作法</a></li><li><a aria-current="page" class="active" href="/blog-worklife/python自动化办公实战课">python自动化办公实战课</a></li><li><a href="/blog-worklife/人人都用得上的写作课">人人都用得上的写作课</a></li><li><a href="/blog-worklife/体验设计案例课">体验设计案例课</a></li><li><a href="/blog-worklife/基于人因的用户体验设计课">基于人因的用户体验设计课</a></li><li><a href="/blog-worklife/打造爆款短视频">打造爆款短视频</a></li><li><a href="/blog-worklife/用户体验设计实战课">用户体验设计实战课</a></li><li><a href="/blog-worklife/程序员的个人财富课">程序员的个人财富课</a></li><li><a href="/blog-worklife/程序员进阶攻略">程序员进阶攻略</a></li><li><a href="/blog-worklife/讲好故事">讲好故事</a></li><li><a href="/blog-worklife/跟着高手学复盘">跟着高手学复盘</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-worklife/python自动化办公实战课">python自动化办公实战课</a></li><li><a href="/blog-worklife/python自动化办公实战课/01.课前必读">01.课前必读</a><ul><li><a href="/blog-worklife/python自动化办公实战课/01.课前必读/01"><span>开篇词 | 重复工作这么多，怎样才能提高工作效率？</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/01.课前必读/02"><span>导读｜入门Python的必备知识</span></a></li></ul></li><li><a href="/blog-worklife/python自动化办公实战课/02.“输入”模块不同文件类型的批量合并和拆分问题">02.“输入”模块不同文件类型的批量合并和拆分问题</a><ul><li><a href="/blog-worklife/python自动化办公实战课/02.“输入”模块不同文件类型的批量合并和拆分问题/01"><span>01 | 拆分与合并：如何快速地批量处理内容相似的Excel？</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/02.“输入”模块不同文件类型的批量合并和拆分问题/02"><span>02｜善用Python扩展库：如何批量合并多个文档？</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/02.“输入”模块不同文件类型的批量合并和拆分问题/03"><span>03｜图片转文字：如何提高识别准确率？</span></a></li></ul></li><li><a href="/blog-worklife/python自动化办公实战课/03.春节特别放送">03.春节特别放送</a><ul><li><a href="/blog-worklife/python自动化办公实战课/03.春节特别放送/01"><span>春节特别放送1｜实体水果店转线上销售的数据统计问题</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/03.春节特别放送/02"><span>春节特别放送2｜用自顶至底的思路解决数据统计问题</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/03.春节特别放送/03"><span>春节特别放送3｜揭晓项目作业的答案</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-worklife/python自动化办公实战课/04.“运算”模块扩展常用的统计、搜索和排序功能">04.“运算”模块扩展常用的统计、搜索和排序功能</a><ul><li><a href="/blog-worklife/python自动化办公实战课/04.“运算”模块扩展常用的统计、搜索和排序功能/01"><span>04 |  函数与字典：如何实现多次替换</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/04.“运算”模块扩展常用的统计、搜索和排序功能/02"><span>05 | 图像处理库：如何实现长图拼接？</span></a></li><li><a aria-current="page" class="active" href="/blog-worklife/python自动化办公实战课/04.“运算”模块扩展常用的统计、搜索和排序功能/03"><span>06 | jieba分词：如何基于感情色彩进行单词数量统计？</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/04.“运算”模块扩展常用的统计、搜索和排序功能/04"><span>07｜快速读写文件：如何实现跨文件的字数统计？</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/04.“运算”模块扩展常用的统计、搜索和排序功能/05"><span>08｜正则表达式：如何提高搜索内容的精确度？</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/04.“运算”模块扩展常用的统计、搜索和排序功能/06"><span>09｜扩展搜索：如何快速找到想要的文件？</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/04.“运算”模块扩展常用的统计、搜索和排序功能/07"><span>10｜按指定顺序给词语排序，提高查找效率</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/04.“运算”模块扩展常用的统计、搜索和排序功能/08"><span>11 ｜通过程序并行计算，避免CPU资源浪费</span></a></li></ul></li><li><a href="/blog-worklife/python自动化办公实战课/05.“控制”模块增强办公软件及周边软硬件的交互能力">05.“控制”模块增强办公软件及周边软硬件的交互能力</a><ul><li><a href="/blog-worklife/python自动化办公实战课/05.“控制”模块增强办公软件及周边软硬件的交互能力/01"><span>12｜文本处理函数：三招解决数据对齐问题</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/05.“控制”模块增强办公软件及周边软硬件的交互能力/02"><span>13｜Excel插件：如何扩展Excel的基本功能？</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/05.“控制”模块增强办公软件及周边软硬件的交互能力/03"><span>14｜VBA脚本编程：如何扩展Excel，实现文件的批量打印？</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/05.“控制”模块增强办公软件及周边软硬件的交互能力/04"><span>15｜PowerShell脚本：如何实现文件批量处理的自动化？</span></a></li></ul></li><li><a href="/blog-worklife/python自动化办公实战课/06.“存储”模块和文件相关的常用操作">06.“存储”模块和文件相关的常用操作</a><ul><li><a href="/blog-worklife/python自动化办公实战课/06.“存储”模块和文件相关的常用操作/01"><span>16｜循环与文件目录管理：如何实现文件的批量重命名？</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/06.“存储”模块和文件相关的常用操作/02"><span>17｜不同操作系统下，如何通过网络同步文件？</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/06.“存储”模块和文件相关的常用操作/03"><span>18｜http库：如何批量下载在线内容，解放鼠标（上）？</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/06.“存储”模块和文件相关的常用操作/04"><span>19｜http库：如何批量下载在线内容，解放鼠标（下）？</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/06.“存储”模块和文件相关的常用操作/05"><span>20｜不同文件混在一起，怎么快速分类？</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/06.“存储”模块和文件相关的常用操作/06"><span>21｜SQLite文本数据库：如何进行数据管理（上）？</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/06.“存储”模块和文件相关的常用操作/07"><span>22｜SQLite文本数据库：如何进行数据管理（下）？</span></a></li></ul></li><li><a href="/blog-worklife/python自动化办公实战课/07.“输出”模块智能化输出自己的工作成果">07.“输出”模块智能化输出自己的工作成果</a><ul><li><a href="/blog-worklife/python自动化办公实战课/07.“输出”模块智能化输出自己的工作成果/01"><span>23｜怎么用数据透视表更直观地展示汇报成果？</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/07.“输出”模块智能化输出自己的工作成果/02"><span>24｜条形、饼状、柱状图最适合用在什么场景下？</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/07.“输出”模块智能化输出自己的工作成果/03"><span>25｜图表库：想要生成动态图表，用Echarts就够了</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/07.“输出”模块智能化输出自己的工作成果/04"><span>26｜快速提取图片中的色块，模仿一张大师的照片</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/07.“输出”模块智能化输出自己的工作成果/05"><span>27｜zipfile压缩库：如何给数据压缩&amp;加密备份？</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/07.“输出”模块智能化输出自己的工作成果/06"><span>28｜Celery库：让计算机定时执行任务，解放人力</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/07.“输出”模块智能化输出自己的工作成果/07"><span>29｜网络和邮件库：定时收发邮件，减少手动操作</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/07.“输出”模块智能化输出自己的工作成果/08"><span>30｜怎么快速把任意文件格式转成PDF，并批量加水印？</span></a></li></ul></li><li><a href="/blog-worklife/python自动化办公实战课/08.结束语">08.结束语</a><ul><li><a href="/blog-worklife/python自动化办公实战课/08.结束语/01"><span>结课测试题｜这些Python自动化办公的知识你都掌握了吗？</span></a></li><li><a href="/blog-worklife/python自动化办公实战课/08.结束语/02"><span>结束语｜和我一起成为10X效率职场人</span></a></li></ul></li><li><a href="/blog-worklife/python自动化办公实战课/summary">python自动化办公实战课</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="06--jieba分词如何基于感情色彩进行单词数量统计"><a aria-hidden="true" tabindex="-1" href="/blog-worklife/python自动化办公实战课/04.“运算”模块扩展常用的统计、搜索和排序功能/03#06--jieba分词如何基于感情色彩进行单词数量统计"><span class="icon icon-link"></span></a>06 | jieba分词：如何基于感情色彩进行单词数量统计？</h1><p>你好，我是尹会生。</p><p>在涉及运营、市场的工作中，我们经常需要根据产品评论的情感分析，来了解某一产品的口碑。所谓的情感分析，就是指根据用户对产品的评论，分析出用户对产品的喜好程度。</p><p>最简单的，我们会<strong>区分产品的评价是正向还是负向</strong>的，然后根据反馈结果改变产品的特性。稍微复杂一点的，我们会<strong>根据情感色彩将产品的评价关键词提取出来，进行统计和分类（用于更深入的分析产品）。</strong></p><p>如果靠人工对产品评价进行辨析，有很大的局限性：一个是不够公平，因为每个人对词语感情色彩的理解并不是完全一致的；另一个是产品评价有很多，而且还会不定期增加，人工分析很难保证及时性。</p><p>因此，在进行词语的情感分析时，我通常都会使用Python的jieba库，来自动化实现文本情感分析功能。一般需要经过三个步骤，分别是<strong>分词、优化分词结果和情感分析</strong>。</p><p>那我就先带你看看<strong>为什么要进行分词，以及如何进行分词操作。</strong></p><h1 id="如何分词"><a aria-hidden="true" tabindex="-1" href="/blog-worklife/python自动化办公实战课/04.“运算”模块扩展常用的统计、搜索和排序功能/03#如何分词"><span class="icon icon-link"></span></a>如何分词？</h1><p>要想判断一段话表达的情感是正向还是负向，就需要根据这句话中的关键词来得到情感的倾向。例如一段话中出现了“开心”“高兴”“物超所值”等正向的词语，我们就可以认定这条产品的评价是偏正向的。相反，出现“不喜欢”“差”等词语，评价就是偏负向的。</p><p>但是，要想从一句话中将这些表达情感的词一个一个找出来，就需要依靠专业的工具把一句话根据语义划分成多个词，再把表达情感的词语提取出来，进行情感分析。</p><p>为什么要先根据语义来划分词呢？这主要是因为中文句子里的每个词中间没有用空格进行分隔，没有分隔就没法进行之后的情感分析。而对中文句子按照语义进行切割的这种操作，我们就称为“分词”。</p><p>Python中有非常成熟的分词库，其中最流行的库是jieba库。在计算机中，实现语义分割的技术有两种，一种是从统计学的角度分词，另一种是从词库的角度基于TF-IDF算法实现分词。jieba就是采用第二种，基于词库的角度对文章进行自动分词的。</p><p>那我就以电商网站上的一段商品评论为例，给你演示一下jieba库是如何实现分词的。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">import jieba</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">    words1=&quot;速度快，包装好，看着特别好，喝着肯定不错！价廉物美&quot;</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">    words2 = jieba.cut(words1)</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">    print(&quot;/&quot;.join(words2))</span></div><div class="token-line"><span class="token plain">    # 速度/快/，/包装/好/，/看着/特别/好/，/喝/着/肯定/不错/！/价廉物美</span></div></pre></div><p>在这段代码中，我利用jieba库的cut()函数实现了自动分词功能。我刚才讲了，jieba分词是依靠词库实现的，词库里包含了提前准备好的词和词性。下图就是jieba词库的内容：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">一鼓 ru</span></div><div class="token-line"><span class="token plain">    一鼓作气 ru</span></div><div class="token-line"><span class="token plain">    一马当先 ru</span></div><div class="token-line"><span class="token plain">    ... ...</span></div></pre></div><p>这些词库中的词，jieba是怎么识别的呢？</p><p>在你使用pip命令安装了jieba库之后，它会附带一个默认的词库。在官方文档中，将这个词库称作“字典”文件。这个文件包含了日常汉语的词语、词性。jieba库会先基于“字典”对文章中所有可能出现的词进行匹配。匹配之后，会生成句子中的汉字所有可能形成的词。然后再将这些词构成的有向无环图（DAG），并采用动态规划算法查找最大概率路径，尽可能不会将一个词拆分成单个汉字。最后再从“字典”找出基于词频的最大切分组合，把这分词的组合从句子中找出来，形成一个一个的词。</p><p>而且，为了提高分词的准确率，jieba对没有记录在字典的词（称作未登录词）也使用了分词的模型，它就是大名鼎鼎的基于汉字成词能力的HMM模型（隐马尔可夫模型）。对词库中的词和未登录词进行处理之后，jieba就可以实现自动化分词了。</p><p>不过，分词之后，我们还需要对分词结果进行优化。因为在分词结果中存在着大量的标点符号，还有“看着”“喝着”“包装” 等和表达产品评价的情感无关的词语，为了加快计算词语的情感速度、避免无关词语影响情感倾向判断，我们就要优化分词的结果。</p><h1 id="优化分词结果"><a aria-hidden="true" tabindex="-1" href="/blog-worklife/python自动化办公实战课/04.“运算”模块扩展常用的统计、搜索和排序功能/03#优化分词结果"><span class="icon icon-link"></span></a>优化分词结果</h1><p>优化分词结果主要从两个方面进行优化：一方面是移除标点符号；一方面是删除和情感无关的助词、名词等。</p><p>我先来带你学习下怎么从分词结果中移除标点符号。</p><p>移除标点符号一般有两种方法：</p><ol><li>删除停止词（Stop Words）；</li><li>根据词性提取关键词。</li></ol><p>先来看看第一种，删除停止词。</p><p>所谓的停止词，就是指<strong>为了节省空间和提高匹配词语情感倾向的效率，在进****行情感分析前自动过滤掉的某些字或词。</strong></p><p>停止词主要是标点符号，也可以是“啊呀呢”等语气助词。把标点符号写入停止词列表后，再使用for循环功能，将jieba分好的词和停止词列表依次匹配。如果jieba分好的词出现在列表中，就将这些词删掉。如果没有出现在列表中，就把这些词再组合成一个新的列表，后续就可以对新的列表进行情感分析。</p><p>删除停止词的代码如下。通过删除停止词，我们就可以得到只有汉字的分词结果。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">words2 = jieba.cut(words1)</span></div><div class="token-line"><span class="token plain">    words3 = list(words2)</span></div><div class="token-line"><span class="token plain">    print(&quot;/&quot;.join(words3))</span></div><div class="token-line"><span class="token plain">    # 速度/快/，/包装/好/，/看着/特别/好/，/喝/着/肯定/不错/！/价廉物美</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">    stop_words = [&quot;，&quot;, &quot;！&quot;]</span></div><div class="token-line"><span class="token plain">    words4 =[x for x in words3 if x not in stop_words]</span></div><div class="token-line"><span class="token plain">    print(words4)</span></div><div class="token-line"><span class="token plain">    # [&#x27;速度&#x27;, &#x27;快&#x27;, &#x27;包装&#x27;, &#x27;好&#x27;, &#x27;看着&#x27;, &#x27;特别&#x27;, &#x27;好&#x27;, &#x27;喝&#x27;, &#x27;着&#x27;, &#x27;肯定&#x27;, &#x27;不错&#x27;, &#x27;价廉物美&#x27;]</span></div></pre></div><p>另一种优化分词结果的方式叫做根据词性提取关键词。这种方式的优点在于不用事先准备停用词列表，jieba库就能够根据每个词的词性对其进行标注。</p><p>我这里为你提供了一张paddle（paddle是百度开源的深度学习平台，jieba使用了paddle的模型库）模式词性表作为参考，你可以根据jieba自动分析得到的词性结果，手动将助词、虚词（标点符号）移除。</p><p><img src="/blog-worklife/static/httpsstatic001geekbangorgresourceimagede5adec72024563b5179f08b5c314a59da5a.f33c8313.png" alt=""/><br/>我把这个基于词性移除标点符号的代码也提供给你：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain"># words5 基于词性移除标点符号</span></div><div class="token-line"><span class="token plain">    import jieba.posseg as psg  </span></div><div class="token-line"><span class="token plain">    words5 = [ (w.word, w.flag) for w in psg.cut(words1) ]</span></div><div class="token-line"><span class="token plain">    # 保留形容词</span></div><div class="token-line"><span class="token plain">    saved = [&#x27;a&#x27;,]</span></div><div class="token-line"><span class="token plain">    words5 =[x for x in words5 if x[1] in saved]</span></div><div class="token-line"><span class="token plain">    print(words5)</span></div><div class="token-line"><span class="token plain">    # [(&#x27;快&#x27;, &#x27;a&#x27;), (&#x27;好&#x27;, &#x27;a&#x27;), (&#x27;好&#x27;, &#x27;a&#x27;), (&#x27;不错&#x27;, &#x27;a&#x27;)]</span></div></pre></div><p>在这段代码中，我在使用jieba库的posseg类实现分词的同时，也对词性进行了标注。为了让你看到更直接的结果，我只保留了形容词，因此，变量saved的列表参数就只有一个‘a’，表示保留的词类型为形容词。</p><p>如果你希望保留更多的词性，可以将词性表中代表每种词的英文缩写写入saved列表中，其中，我建议你在处理之后把形容词、副词、动词都保留下来，这些都有助于你进行下一步的语义情感分析。</p><p>在优化分词结果之后，我们就得到了只有形容词的处理结果。那么，接下来，我们需要基于这些形容词来获取产品评价的正向或负向结果，以及基于词语的情感色彩来统计单词的数量。</p><h1 id="语义情感分析"><a aria-hidden="true" tabindex="-1" href="/blog-worklife/python自动化办公实战课/04.“运算”模块扩展常用的统计、搜索和排序功能/03#语义情感分析"><span class="icon icon-link"></span></a>语义情感分析</h1><p>对于已经分好词的语句，我们需要使用另一个库统计词的正向、负向情感倾向，这个库就是snownlp库。</p><p>snownlp库既能实现分词，也能计算词出现频率，以及进行情感分析。那你可能就发出疑问了：为什么不直接使用snownlp进行分词，而要使用jieba分词呢？</p><p>原因就在于，snownlp的算法问题，会让它对否定词划分得不够准确。例如“不喜欢”，snownlp会把这个词划分为两个独立的词，分别是“不”和“喜欢”。那么，在计算语义情感时，就会产生较大的误差。所以我们会先采用jieba进行分词，分词之后再采用snownlp来实现语义情感分析功能。</p><p>接下来，我带你看一下如何使用snownlp得到完成分词之后的情感分析结果。代码如下：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">from snownlp import SnowNLP</span></div><div class="token-line"><span class="token plain">    words6 = [ x[0] for x in words5 ]</span></div><div class="token-line"><span class="token plain">    s1 = SnowNLP(&quot; &quot;.join(words3))</span></div><div class="token-line"><span class="token plain">    print(s1.sentiments)</span></div><div class="token-line"><span class="token plain">    # 0.99583439264303</span></div></pre></div><p>这段代码通过snownlp的Bayes（贝叶斯）模型训练方法，将模块自带的正样本和负样本读入内存之后，再使用Bayes模型中的classify()函数进行分类，这样就得到了sentiments属性的值，sentiments的值表示情感倾向的方向。在snownlp中：</p><ul><li>如果情感倾向是正向的，sentiments的结果会接近1。</li><li>如果情感倾向是负向的，结果会接近0。</li></ul><p>可以看到，我们在刚刚的代码中得到的情感分析的结果是0.9958，非常接近1，因此这条产品的评价就是正向的。</p><p>情感倾向结果趋近于1或者趋近于0都是非常理想的情况，可以直接得到感情色彩比较强烈的产品评价。但是，有时候感情色彩不太强烈，在这种情况下，我们就需要根据评价的数值范围对评论进行分组，统计每组包含多少个评价。</p><p>这个功能也可以通过snownlp实现，我把代码写在这里，你可以参考：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">positive = 0</span></div><div class="token-line"><span class="token plain">    negtive = 0</span></div><div class="token-line"><span class="token plain">    for word in words6:</span></div><div class="token-line"><span class="token plain">        s2 = SnowNLP(word)</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">        if s2.sentiments &gt; 0.7:</span></div><div class="token-line"><span class="token plain">            positive+=1</span></div><div class="token-line"><span class="token plain">        else:</span></div><div class="token-line"><span class="token plain">            negtive+=1</span></div><div class="token-line"><span class="token plain">    </span></div><div class="token-line"><span class="token plain">        print(word,str(s2.sentiments))</span></div><div class="token-line"><span class="token plain">    print(f&quot;正向评价数量:{positive}&quot;)</span></div><div class="token-line"><span class="token plain">    print(f&quot;负向评价数量:{negtive}&quot;)</span></div><div class="token-line"><span class="token plain">    # 快 0.7164835164835165</span></div><div class="token-line"><span class="token plain">    # 好 0.6558628208940429</span></div><div class="token-line"><span class="token plain">    # 好 0.6558628208940429</span></div><div class="token-line"><span class="token plain">    # 不错 0.8612132352941176</span></div><div class="token-line"><span class="token plain">    # 价廉物美 0.7777777777777779</span></div><div class="token-line"><span class="token plain">    # 正向评价数量:3</span></div><div class="token-line"><span class="token plain">    # 负向评价数量:2</span></div></pre></div><p>通过snownlp库配合jieba分词的结果，你就可以实现批量产品评论的自动语义情感分析了。同时，你还可以根据不断累积产品的评价，来持续优化你的产品。</p><h1 id="小结"><a aria-hidden="true" tabindex="-1" href="/blog-worklife/python自动化办公实战课/04.“运算”模块扩展常用的统计、搜索和排序功能/03#小结"><span class="icon icon-link"></span></a>小结</h1><p>最后，我来为你总结一下对文件进行情感倾向分析的关键步骤和注意事项。实现语义情感分析功能，你必须掌握分词、优化分词结果、语义情感分析这三个步骤。</p><p>其中分词是实现中文语义分析的第一步，也是最基础的部分。分词的好坏决定了对每个词的情感进行标注的准确程度。如果默认的jieba分词没有正确地把词语划分，你也可以使用jieba自带的suggest_freq()函数进行词频调节。</p><p>举个小例子，“中”“将”两个字可以组成“中将”的词语，也可以拆开来用“我们中/将有人成功考上北大”。在不同的语言环境中，我们要通过词频调节来让它们以词的形式出现，还是以两个字的方式出现。调整的方法是：</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">jieba.suggest_freq((&quot;中&quot;, &quot;将&quot;), tune = True)</span></div></pre></div><p>可以看到，利用调节词频使“中”“将”都能被分出来，而不会被错误地识别为一个词“中将”，通过这种方式，就可以提升jieba的识别正确率。</p><p>在优化分词结果这一步，你可以通过减少虚词和标点符号，通过停止词、词性的选择，来降低它们对情感分析结果的干扰。</p><p>最后，你还可以为snownlp增加新的流行词和网络用语，帮你更准确地分析用户对产品的喜好程度，从而提高产品定位的精确度。</p><p>在snownlp中，通过train()和 save()两个函数把模型训练和保存之后，就能实现扩展默认字典的功能了。此外，我在工作中还会利用这种方式增加emoji表情对应的情感倾向分析功能，以此来进一步提升snownlp分析情感倾向的准确度。</p><p>我将训练模型和保存训练后的模型的函数也写在这里供你参考，希望通过训练自己的模型，能够让你的产品分析更加准确。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">sentiment.train(neg2.txt,pos2.txt);  #   训练用户自定义正负情感数据集</span></div><div class="token-line"><span class="token plain">    sentiment.save(&#x27;sentiment2.marshal&#x27;);  # 保存训练模型</span></div></pre></div><p>今天用到的代码，我都放在了 GitHub 上，你可以点击<a target="_blank" rel="noopener noreferrer" href="https://github.com/wilsonyin123/python_productivity/blob/main/%E6%96%87%E7%AB%A06%E4%BB%A3%E7%A0%81.zip">这个链接<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>查看。</p><h1 id="思考题"><a aria-hidden="true" tabindex="-1" href="/blog-worklife/python自动化办公实战课/04.“运算”模块扩展常用的统计、搜索和排序功能/03#思考题"><span class="icon icon-link"></span></a>思考题</h1><p>我给你留一道思考题，我在最后一段代码分别统计了正向和负向评价的数量，你能否根据这段代码统计一段文字中包含了多少个动词、多少个名词和多少个形容词呢？欢迎你在课程评论区留言，和我一起讨论。</p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/ssrc/python自动化办公实战课/04.“运算”模块扩展常用的统计、搜索和排序功能/03.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/29 14:28:22</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-worklife/umi.4ad44284.js"></script>
  </body>
</html>
